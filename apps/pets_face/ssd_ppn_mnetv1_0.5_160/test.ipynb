{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "from IPython import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.825256\n",
      "1.4318237\n"
     ]
    }
   ],
   "source": [
    "testimage = PIL.Image.open('test_images/4.jpg')\n",
    "imgs = []\n",
    "imgs.append(np.array(testimage.resize((160,160))).astype(np.float32)/128-1)\n",
    "imgs = np.array(imgs)\n",
    "\n",
    "tensorname = 'FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold'\n",
    "gd = tf.GraphDef.FromString(open(\"inference/tflite_graph.pb\", 'rb').read())\n",
    "inp, x = tf.import_graph_def(gd, return_elements = ['normalized_input_image_tensor:0', tensorname+':0'])\n",
    "\n",
    "with tf.Session(graph=inp.graph) as sess:\n",
    "    x = sess.run(x, feed_dict={inp: imgs})\n",
    "    \n",
    "print(np.min(x))\n",
    "print(np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for filename in os.listdir('image'):\n",
    "#     imgs.append(np.array(PIL.Image.open('image/'+filename).resize((160,160))).astype(np.float32) / 128 - 1)\n",
    "#     ids.append(int(filename.split('_')[2].split('.')[0]))\n",
    "    \n",
    "# imgs = np.array(imgs)\n",
    "testimage = PIL.Image.open('test_images/4.jpg')\n",
    "imgs = []\n",
    "imgs.append(np.array(testimage.resize((160,160))).astype(np.float32)/128-1)\n",
    "imgs = np.array(imgs)\n",
    "\n",
    "# tensorname = 'convert_scores'\n",
    "gd = tf.GraphDef.FromString(open(\"inference/tflite_graph.pb\", 'rb').read())\n",
    "inp, x, y = tf.import_graph_def(gd, return_elements = \n",
    "    ['normalized_input_image_tensor:0', 'convert_scores:0', 'concat:0'])\n",
    "\n",
    "with tf.Session(graph=inp.graph) as sess:\n",
    "    scores, box_preds = sess.run([x,y], feed_dict={inp: imgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14544197057407338, 0.25922437696264433, 0.6004415299370112, 0.8322575628533653]\n"
     ]
    }
   ],
   "source": [
    "pred_id = np.argmax(scores[0,:,1])\n",
    "encoded_box = box_preds[0,pred_id,:] # [ty,tx,th,tw]\n",
    "anchor_box = get_anchor_box(pred_id) # [ycenter,xcenter,h,w]\n",
    "\n",
    "box = decode(encoded_box, anchor_box)\n",
    "\n",
    "draw_bbox(testimage, box)\n",
    "\n",
    "print(decode(encoded_box, anchor_box))\n",
    "\n",
    "# print('box_preds', box_preds[0,pred_id,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order of Box/Class prediction tensor\n",
    "#### 1. Class predictors\n",
    "Before reshape & concat:\n",
    "\n",
    "**H x W x Anchors x Classes**\n",
    "\n",
    "After reshape & concat:\n",
    "\n",
    "**\\[H1xW1xAnchors H2xW2xAnchors ... H5xW5xAnchors\\]xClasses**  (1,834,2)\n",
    "\n",
    "#### 2. Box predictors\n",
    "Before reshape & concat:\n",
    "\n",
    "**H x W x Anchors x 4**\n",
    "\n",
    "After reshape & concat:\n",
    "\n",
    "**\\[H1xW1xAnchors H2xW2xAnchors ... H5xW5xAnchors\\]x4**  (1,834,4)\n",
    "\n",
    "#### 3. Anchors\n",
    "- num_layers: 5\n",
    "- min_scale: 0.2\n",
    "- max_scale: 0.95\n",
    "- aspect_ratios: 1.0\n",
    "- aspect_ratios: 2.0\n",
    "- aspect_ratios: 0.5\n",
    "- aspect_ratios: 3.0\n",
    "- aspect_ratios: 0.3333\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fmap_size(fmap_id):\n",
    "    fmap_size = [\n",
    "        [10,10],\n",
    "        [5,5],\n",
    "        [3,3],\n",
    "        [2,2],\n",
    "        [1,1]\n",
    "    ]\n",
    "    return fmap_size[fmap_id]\n",
    "\n",
    "def get_anchor_box(pred_id):\n",
    "    anchor_box_id = pred_id%6 # 6 anchor boxes per pixel\n",
    "    pixel_id = np.floor(pred_id/6)\n",
    "    \n",
    "    if pixel_id < 100: \n",
    "        fmap_id = 0\n",
    "    elif pixel_id < 125:\n",
    "        fmap_id = 1\n",
    "        pixel_id -= 100\n",
    "    elif pixel_id < 134:\n",
    "        fmap_id = 2\n",
    "        pixel_id -= 125\n",
    "    elif pixel_id < 138:\n",
    "        fmap_id = 3\n",
    "        pixel_id -= 134\n",
    "    else:\n",
    "        fmap_id = 4\n",
    "        pixel_id -= 138\n",
    "        \n",
    "    fmap_size = get_fmap_size(fmap_id)\n",
    "        \n",
    "    anchor_box_pos = [np.floor(pixel_id/fmap_size[1]), pixel_id%fmap_size[1]]\n",
    "    anchor_box_center = [(anchor_box_pos[0]+0.5)/fmap_size[0], (anchor_box_pos[1]+0.5)/fmap_size[1]]\n",
    "    # anchor box center is in [H,W]\n",
    "    xcenter_a = anchor_box_center[1]\n",
    "    ycenter_a = anchor_box_center[0]\n",
    "    \n",
    "    ## calculate wa and ha\n",
    "    s = 0.2+(0.95-0.2)/4*np.array([0,1,2,3,4])\n",
    "    s = list(s)+[1.0]\n",
    "    \n",
    "    scale = s[fmap_id]\n",
    "    scale_next = s[fmap_id+1]\n",
    "    \n",
    "    ar = [1.0, 2.0, 0.5, 3.0, 0.3333]\n",
    "    if anchor_box_id == 5: # the last square box\n",
    "        wa = ha = np.sqrt(scale*scale_next)\n",
    "    else:\n",
    "        wa = scale*np.sqrt(ar[anchor_box_id])\n",
    "        ha = scale/np.sqrt(ar[anchor_box_id])\n",
    "    \n",
    "    return [ycenter_a, xcenter_a, ha, wa]\n",
    "\n",
    "def decode(encoded_box, anchor_box):\n",
    "    # encoded_box: [ty,tx,th,tw]\n",
    "    # anchor_box: [ycentera,xcentera,ha,wa]\n",
    "    ty = encoded_box[0]\n",
    "    tx = encoded_box[1]\n",
    "    th = encoded_box[2]\n",
    "    tw = encoded_box[3]\n",
    "    \n",
    "    ycenter_a = anchor_box[0]\n",
    "    xcenter_a = anchor_box[1]\n",
    "    ha        = anchor_box[2]\n",
    "    wa        = anchor_box[3]\n",
    "    \n",
    "    scale_factors = [10.0,10.0,5.0,5.0]\n",
    "    \n",
    "    ty /= scale_factors[0]\n",
    "    tx /= scale_factors[1]\n",
    "    th /= scale_factors[2]\n",
    "    tw /= scale_factors[3]\n",
    "    \n",
    "    w = np.exp(tw) * wa\n",
    "    h = np.exp(th) * ha\n",
    "    ycenter = ty * ha + ycenter_a\n",
    "    xcenter = tx * wa + xcenter_a\n",
    "    ymin = ycenter - h / 2.\n",
    "    xmin = xcenter - w / 2.\n",
    "    ymax = ycenter + h / 2.\n",
    "    xmax = xcenter + w / 2.   \n",
    "    \n",
    "    return [ymin,xmin,ymax,xmax]\n",
    "\n",
    "def draw_bbox(image, box):\n",
    "    ymin = box[0]\n",
    "    xmin = box[1]\n",
    "    ymax = box[2]\n",
    "    xmax = box[3]\n",
    "    draw = PIL.ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width=2, fill='red')\n",
    "    image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
